# FX Rate Forecasting Pipeline

This repository contains a research-oriented pipeline for **directional FX forecasting**, currently focused on the **USD/CAD** pair at a **daily (business-day)** frequency.

The project is explicitly framed around:
- probabilistic **directional prediction** (UP / DOWN),
- **selective decision-making** via confidence gating,
- stability, calibration, and interpretability over raw accuracy.

This is **not** a point-forecasting system and does not attempt to maximize headline accuracy.

---

## Project Scope and Framing

### Key design choices
- **Target**: Direction of cumulative return over a 7-business-day horizon.
- **Output**: Probabilities, not point estimates.
- **Evaluation philosophy**:
  - Weak signals are acceptable if they are stable and well-characterized.
  - Acting less often (abstaining) is preferable to acting noisily.
  - Decision logic is treated as a first-class layer, separate from modeling.

---

## Data Contract

### FX Pair
- USD/CAD

### Frequency
- Daily (business days only)
- Weekend gaps are expected and validated

### Gold Layer Schema (strict)
Each gold parquet file must contain:

| Column        | Description                                  |
|---------------|----------------------------------------------|
| `obs_date`    | Observation date (business day)              |
| `series_id`   | Single identifier per file                   |
| `value`       | FX rate value                                |
| `prev_value`  | Exact lag-1 value (no gaps, no recomputation)|

Any deviation from this contract is treated as an error.

---

## Gold Data Source (Read-Only)

This project consumes **Gold-layer FX data** produced by an upstream ingestion pipeline.

Key properties:
- Gold data is **authoritative and immutable**
- This repository **does not generate raw FX data**
- All modeling, evaluation, and artifacts assume the Gold contract is already satisfied

For local research and development, Gold data can be synced into a local parquet file via a small CLI utility.  
The local copy is treated as **read-only input** and is excluded from version control.

---

## Syncing Gold Data Locally

Gold data can be downloaded locally using the provided sync script.

Example (USD/CAD):

```bash
python -m scripts.sync_gold \
  --series FXUSDCAD \
  --out data/data-USD-CAD.parquet \
  --with-watermark
```
This command:
- downloads the latest Gold parquet for the requested series,
- optionally retrieves the associated watermark metadata,
- writes a local, UI-ready parquet file for downstream notebooks and scripts.


## Production: GitHub Actions Daily Run

The pipeline runs automatically via GitHub Actions on a daily schedule (6:00 AM UTC).

### Required GitHub Secrets

- **`AWS_ROLE_ARN`**: ARN of the IAM role to assume via OIDC (e.g., `arn:aws:iam::123456789012:role/github-actions-h7-pipeline`)

### Required AWS Setup

The IAM role must have the following permissions:

**S3 Permissions:**
- `s3:GetObject` and `s3:ListBucket` on `gold/*` (for syncing gold data)
- `s3:GetObject` on `models/h7/*` (for downloading model artifacts)
- `s3:PutObject` (and optionally `s3:DeleteObject`) on `predictions/h7/*` (for publishing outputs)

**SES Permissions:**
- `ses:SendEmail` and/or `ses:SendRawEmail` in `us-east-2` region

**OIDC Trust Policy:**
The role must trust the GitHub OIDC provider:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Federated": "arn:aws:iam::123456789012:oidc-provider/token.actions.githubusercontent.com"
      },
      "Action": "sts:AssumeRoleWithWebIdentity",
      "Condition": {
        "StringEquals": {
          "token.actions.githubusercontent.com:aud": "sts.amazonaws.com"
        },
        "StringLike": {
          "token.actions.githubusercontent.com:sub": "repo:OWNER/REPO:*"
        }
      }
    }
  ]
}
```

### SES Sandbox Constraints

If using SES in sandbox mode:
- Both `from_email` and all `to_emails` must be verified identities in SES
- To move out of sandbox, request production access in the SES console

### Model Artifacts

The workflow downloads model artifacts from S3 before running inference:
- **S3 Location**: `s3://fx-rate-pipeline-dev/models/h7/`
- **Required Files**:
  - `logreg_h7_global.joblib` - Trained logistic regression model
  - `features_h7.json` - Feature specification
  - `metadata_h7.json` - Model metadata (version, training date, etc.)

These artifacts are generated by the training/export scripts (`src/models/train_export_logreg_h7_global.py`) and must be uploaded to S3 **once** before CI can run.

**One-time upload (from local machine with AWS profile):**
```bash
# Upload model artifacts to S3
aws s3 cp models/logreg_h7_global.joblib s3://fx-rate-pipeline-dev/models/h7/logreg_h7_global.joblib --profile fx-gold --only-show-errors
aws s3 cp models/features_h7.json s3://fx-rate-pipeline-dev/models/h7/features_h7.json --profile fx-gold --only-show-errors
aws s3 cp models/metadata_h7.json s3://fx-rate-pipeline-dev/models/h7/metadata_h7.json --profile fx-gold --only-show-errors
```

**Note**: After initial upload, artifacts are only re-uploaded when the model is retrained. The CI workflow downloads them on every run.

### Manual Trigger

The workflow can be manually triggered via GitHub Actions UI:
- Go to Actions → H7 Daily Pipeline → Run workflow
- Optionally enable "Dry run mode" to validate config without executing

### Workflow Artifacts

Outputs are uploaded as workflow artifacts (retained for 7 days) for debugging:
- `outputs/runs/{run_date}/` - Run-specific outputs
- `outputs/latest/` - Latest promoted outputs

## Repository Structure

```text
FX-Rate-Forecasting-Pipeline
│
├── config/
│   └── pipeline_h7.json              # pipeline configuration
│
├── data/
│   └── data-USD-CAD.parquet          # gold-layer FX data (local, ignored)
│
├── notebooks/
│   ├── 01_gold_loader_and_qc.ipynb
│   ├── 02_direction_backtest_baselines.ipynb
│   ├── 03_direction_feature_engineering.ipynb
│   ├── 04_logistic_regression_direction.ipynb
│   ├── 05_tree_model_direction.ipynb
│   ├── 06_decision_policy_confidence_gating.ipynb
│   └── 07_probability_calibration.ipynb
│
├── src/
│   ├── artifacts/
│   │   └── write_latest.py           # UI-ready artifact writer
│   └── pipeline/
│       ├── config.py                 # configuration schema and loader
│       └── run_date.py                # Toronto timezone utilities
│
├── outputs/                          # generated artifacts (git-ignored)
│
├── requirements.txt                  # minimal, intentional dependencies
├── README.md
└── .gitignore

```

---

## Pipeline Configuration

The pipeline uses a strict configuration schema defined in `config/pipeline_h7.json`. This configuration specifies:

- **Horizon**: Must be `"h7"` (7-business-day horizon)
- **Timezone**: Must be `"America/Toronto"` (all run dates use Toronto wall clock)
- **Series**: List of FX series with local Gold data paths
- **S3**: S3 bucket and key template for Gold data storage
- **Artifacts**: Model artifact locations (model, features, metadata files)
- **Outputs**: Output directory paths for runs and latest artifacts

The configuration loader (`src.pipeline.config.load_pipeline_config`) enforces strict validation:
- Rejects unknown keys (prevents silent config drift)
- Validates all required fields are non-empty
- Ensures S3 prefix templates contain `{series_id}` placeholder
- Validates filenames end with `.parquet` where required

### Run Date Utilities

Run dates are determined using **America/Toronto timezone** (wall clock time). The `src.pipeline.run_date` module provides:

- `toronto_today()`: Returns today's date in Toronto timezone
- `toronto_now_iso()`: Returns current datetime as ISO string in Toronto timezone

These utilities ensure deterministic run date calculation regardless of where the pipeline executes (e.g., UTC servers).

### Testing Pipeline Components

Run tests for pipeline configuration and run date utilities:

```bash
# Test run date utilities
python -m pytest tests/test_run_date_toronto.py -v

# Test configuration schema and loader
python -m pytest tests/test_pipeline_config.py -v
```

---
## Notebook Overview

### 01 — Gold Loader and QC
- Loads gold-layer parquet data.
- Enforces schema, ordering, and lag integrity.
- Validates date continuity (business days only).

---

### 02 — Direction Backtest Baselines
- Defines directional target (7-day horizon).
- Implements naive and heuristic baselines.
- Introduces rolling backtest protocol.
- Evaluates confidence buckets and coverage vs accuracy.

---

### 03 — Direction Feature Engineering
- Leakage-safe feature construction.
- Feature groups include:
  - lagged returns,
  - rolling volatility,
  - momentum and z-scores,
  - regime flags,
  - calendar effects.
- Explicit validation against gold data contract.

---

### 04 — Logistic Regression (Directional Anchor)
- Expanding-window, monthly refit backtest.
- Logistic regression used as an interpretable probability anchor.
- Evaluation includes:
  - overall metrics,
  - confidence buckets,
  - coefficient stability over time.

---

### 05 — Tree-Based Direction Model
- Controlled non-linear model (HistGradientBoosting).
- Same backtest protocol as logistic regression.
- Feature importance inspection.
- Conclusion: non-linear capacity does not materially improve the signal.

---

### 06 — Decision Policy and Confidence Gating
- Introduces a **decision layer** on top of model probabilities.
- Evaluates selective prediction strategies:
  - single-model confidence thresholds,
  - agreement gating (logreg + tree),
  - balanced top-k confidence selection.
- Metrics are computed **only on acted subsets**:
  - conditional accuracy,
  - log loss,
  - Brier score,
  - ECE (Expected Calibration Error).
- Includes:
  - coverage tradeoff curves,
  - regime-conditional diagnostics,
  - rolling 1Y stability analysis,
  - worst-year stress tests.
- Locks a default operating policy based on empirical tradeoffs.

---

### 07 — Post-hoc Probability Calibration

This notebook evaluates **post-hoc probability calibration** under a strictly out-of-sample protocol. Calibration is treated as a probability-quality tool, not a signal-enhancement technique.

#### Calibration protocol
- Expanding-window monthly refit.
- Rolling calibration window drawn strictly from past data.
- Calibrators fit only on historical predictions.
- No leakage into test months.

#### Methods
- Isotonic regression with safe fallback to identity when data is insufficient.

#### Evaluation focuses on
- LogLoss, Brier score, and ECE (10- and 20-bin).
- Reliability (calibration) curves.
- Impact of calibration on decision policies from Notebook 06.

#### Key findings
- Calibration materially improves probability reliability (lower ECE).
- No improvement in directional accuracy.
- Threshold-gating policies may degrade under calibration.
- Probability treatment must be **policy-aware**.

#### Operational takeaway
- Logistic regression:
  - raw probabilities preferred for threshold gating,
  - calibrated probabilities preferred for ranking-based policies.
- Tree models:
  - calibrated probabilities preferred in all cases.

---

## Output Artifacts (UI Contract)

The pipeline produces stable artifacts intended for UI consumption and scheduled inference runs.  
All artifacts are written to `outputs/` and are ignored by git.

### Latest Promotion (Atomic)

Artifacts are promoted to `outputs/latest/` using atomic file operations:
- Multiple files (parquet, JSON manifest) are promoted atomically using temporary directories and `os.replace`
- If any source file is missing or any copy fails, the latest directory remains unchanged
- Each run writes a manifest (`manifest.json`) recording run metadata, file hashes, and data ranges

### Canonical daily artifact (UI-facing)

**`outputs/predictions_latest_h7.parquet`**

One row per business day (`obs_date`) containing probabilities, decisions, and metadata.

#### Stable schema
- `obs_date`
- `pair`
- `horizon_bdays`
- `model_version` (git SHA)
- `p_up_logreg_raw`, `p_up_tree_raw`
- `p_up_logreg_cal`, `p_up_tree_cal`
- `policy_name`
- `policy_params` (JSON)
- `action` ∈ {`UP`, `DOWN`, `ABSTAIN`}
- `confidence` ∈ [0, 1]
- `coverage_target` (nullable)
- `regime` (nullable)

---

### Run metadata

**`outputs/run_metadata_h7.json`**

- `pair`
- `horizon_bdays`
- `as_of_date`
- `data_start`, `data_end`
- `model_version`
- `calibration_enabled`
- `policy_name`
- `policy_params`

---

### Research and diagnostic artifacts

Generated by notebooks for diagnostics and visualization:
- `outputs/decision_policy_sweep.csv`
- `outputs/decision_policy_by_regime.csv`
- `outputs/calibration_metrics_overall.csv`
- `outputs/calibration_reliability_bins.csv`
- `outputs/calibration_policy_sweep.csv`

---

## Current Status and Next Steps

The research pipeline is feature-complete and stable:
- directional modeling,
- confidence-gated decision policies,
- regime-aware diagnostics,
- post-hoc probability calibration.

The signal is weak but stable, and decision behavior is well-characterized.

**Next steps are operational, not statistical**
- scheduled inference (e.g., AWS),
- artifact materialization for UI consumption,
- monitoring for data drift and policy stability.

No further model complexity is planned.

---

## Disclaimer

This repository is for research and experimentation only.  
It does not constitute trading advice or a production trading system.
