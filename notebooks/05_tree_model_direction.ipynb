{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 05 â€” Tree-based Direction Model (USD/CAD)\n",
    "\n",
    "Goal: Evaluate a simple, controlled tree-based classifier for 7-business-day direction\n",
    "using the same expanding-window rolling backtest as Notebook 04.\n",
    "\n",
    "Input:\n",
    "- outputs/usdcad_features_h7.parquet (from Notebook 03)\n",
    "\n",
    "Outputs (written to outputs/, ignored by git):\n",
    "- tree_backtest_rows.csv\n",
    "- tree_metrics_overall.csv\n",
    "- tree_metrics_by_confidence.csv\n",
    "- tree_feature_importance.csv\n"
   ],
   "id": "7e428e4c5e97e99d"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T06:47:57.998780Z",
     "start_time": "2025-12-27T06:47:57.989126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, brier_score_loss\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "RANDOM_SEED = 7\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    start = start or Path.cwd()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"data\").is_dir() and (p / \"src\").is_dir():\n",
    "            return p\n",
    "    raise RuntimeError(f\"Repo root not found from: {start}. Run notebook from inside repo.\")\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "OUT_DIR = REPO_ROOT / \"outputs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "H = 7\n",
    "FEATURE_PATH = OUT_DIR / f\"usdcad_features_h{H}.parquet\"\n",
    "if not FEATURE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Feature parquet not found: {FEATURE_PATH}. Run Notebook 03 first.\")\n",
    "\n",
    "BACKTEST_ROWS_CSV = OUT_DIR / \"tree_backtest_rows.csv\"\n",
    "METRICS_OVERALL_CSV = OUT_DIR / \"tree_metrics_overall.csv\"\n",
    "METRICS_BUCKETS_CSV = OUT_DIR / \"tree_metrics_by_confidence.csv\"\n",
    "IMPORTANCE_CSV = OUT_DIR / \"tree_feature_importance.csv\"\n"
   ],
   "id": "c8c10284d3431854",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:47:58.015206Z",
     "start_time": "2025-12-27T06:47:58.005267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_feat = pd.read_parquet(FEATURE_PATH).sort_index()\n",
    "\n",
    "target_col = f\"direction_{H}d\"\n",
    "excluded = {target_col, f\"fwd_return_{H}d\"}\n",
    "feature_cols = [c for c in df_feat.columns if c not in excluded]\n",
    "\n",
    "X_all = df_feat[feature_cols].copy()\n",
    "y_all = df_feat[target_col].astype(int).copy()\n",
    "\n",
    "df_feat.shape, len(feature_cols), feature_cols[:10]\n"
   ],
   "id": "c4928ecd976963f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1960, 23),\n",
       " 21,\n",
       " ['value',\n",
       "  'ret_1d',\n",
       "  'ret_3d',\n",
       "  'ret_5d',\n",
       "  'ret_10d',\n",
       "  'ret_21d',\n",
       "  'vol_5d',\n",
       "  'vol_10d',\n",
       "  'vol_21d',\n",
       "  'vol_63d'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:47:58.026482Z",
     "start_time": "2025-12-27T06:47:58.023854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_confidence_bucket(p: pd.Series, edges=(0.0, 0.4, 0.45, 0.55, 0.6, 1.0)) -> pd.Series:\n",
    "    labels = []\n",
    "    for i in range(len(edges) - 1):\n",
    "        labels.append(f\"[{edges[i]:.2f},{edges[i+1]:.2f})\" if i < len(edges) - 2 else f\"[{edges[i]:.2f},{edges[i+1]:.2f}]\")\n",
    "    return pd.cut(p, bins=list(edges), labels=labels, include_lowest=True, right=False)\n"
   ],
   "id": "688b2675d30e707c",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model choice\n",
    "\n",
    "XGBoost is optional. If it is not installed, this notebook falls back to\n",
    "`sklearn.ensemble.HistGradientBoostingClassifier` to keep the pipeline runnable.\n",
    "\n",
    "To use XGBoost:\n",
    "`pip install xgboost`\n"
   ],
   "id": "afe8705fb4aabf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:47:58.033657Z",
     "start_time": "2025-12-27T06:47:58.029879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USE_XGBOOST = True\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    xgb_available = True\n",
    "except Exception as e:\n",
    "    xgb_available = False\n",
    "    xgb_err = str(e)\n",
    "\n",
    "if USE_XGBOOST and xgb_available:\n",
    "    MODEL_NAME = \"xgboost\"\n",
    "    # Controlled, conservative defaults:\n",
    "    # - shallow trees\n",
    "    # - modest learning rate\n",
    "    # - no hyperparameter search\n",
    "    # - early stopping is allowed but kept simple\n",
    "    base_model = xgb.XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        min_child_weight=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "else:\n",
    "    MODEL_NAME = \"sklearn_histgb\"\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    # Controlled tree boosting built into sklearn:\n",
    "    base_model = HistGradientBoostingClassifier(\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=300,\n",
    "        min_samples_leaf=20,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "\n",
    "print(\"MODEL_NAME:\", MODEL_NAME)\n",
    "if USE_XGBOOST and not xgb_available:\n",
    "    print(\"XGBoost not available, fallback to sklearn. Import error:\", xgb_err[:200])\n"
   ],
   "id": "b6ef8d691a5a883b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME: xgboost\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:48:04.966465Z",
     "start_time": "2025-12-27T06:47:58.037110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rolling_monthly_backtest_tree(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    model,\n",
    "    min_train_size: int = 252 * 2,\n",
    "    use_early_stopping: bool = False,\n",
    "    eval_slice: int = 252,\n",
    "    early_stopping_rounds: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Expanding-window monthly refit:\n",
    "    - Fit at the start of each month using all prior data (strictly before the month)\n",
    "    - Predict probabilities for all dates in that month\n",
    "\n",
    "    Notes:\n",
    "    - For XGBoost >= 3.x, early stopping via `early_stopping_rounds=` is not supported\n",
    "      in the sklearn wrapper. This function defaults to NO early stopping to keep the\n",
    "      behavior stable across versions.\n",
    "    \"\"\"\n",
    "    idx = X.index\n",
    "    months = pd.PeriodIndex(idx, freq=\"M\")\n",
    "    unique_months = months.unique().sort_values()\n",
    "\n",
    "    rows = []\n",
    "    last_fitted_model = None\n",
    "    last_train_mask = None\n",
    "\n",
    "    for m in unique_months:\n",
    "        in_month = (months == m)\n",
    "        month_idx = idx[in_month]\n",
    "        if len(month_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        # Train strictly before this month\n",
    "        train_mask = idx < month_idx.min()\n",
    "        if train_mask.sum() < min_train_size:\n",
    "            continue\n",
    "\n",
    "        X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "        X_test, y_test = X.loc[in_month], y.loc[in_month]\n",
    "\n",
    "        # Fit model (no early stopping by default for version robustness)\n",
    "        if MODEL_NAME == \"xgboost\" and use_early_stopping:\n",
    "            # Optional: callback-based early stopping (works with newer XGBoost versions)\n",
    "            # Keeps deterministic split: last eval_slice points of training used for eval\n",
    "            try:\n",
    "                from xgboost.callback import EarlyStopping\n",
    "\n",
    "                if len(X_train) >= (eval_slice * 3):\n",
    "                    X_tr, y_tr = X_train.iloc[:-eval_slice], y_train.iloc[:-eval_slice]\n",
    "                    X_ev, y_ev = X_train.iloc[-eval_slice:], y_train.iloc[-eval_slice:]\n",
    "                    model.fit(\n",
    "                        X_tr,\n",
    "                        y_tr,\n",
    "                        eval_set=[(X_ev, y_ev)],\n",
    "                        verbose=False,\n",
    "                        callbacks=[EarlyStopping(rounds=early_stopping_rounds, save_best=True)],\n",
    "                    )\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "            except Exception:\n",
    "                # If callbacks are unavailable for any reason, fall back to plain fit\n",
    "                model.fit(X_train, y_train)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        last_fitted_model = model\n",
    "        last_train_mask = train_mask\n",
    "\n",
    "        # Predict probabilities\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            p_up = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            # Safety fallback (should not happen for classifiers here)\n",
    "            p_up = model.predict(X_test)\n",
    "\n",
    "        y_pred = (p_up >= 0.5).astype(int)\n",
    "\n",
    "        out = pd.DataFrame(\n",
    "            {\n",
    "                \"date\": X_test.index,\n",
    "                \"y_true\": y_test.values,\n",
    "                \"p_up\": p_up,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"month\": str(m),\n",
    "                \"train_end\": month_idx.min() - pd.Timedelta(days=1),\n",
    "                \"n_train\": len(X_train),\n",
    "                \"n_test\": len(X_test),\n",
    "            }\n",
    "        ).set_index(\"date\")\n",
    "\n",
    "        rows.append(out)\n",
    "\n",
    "    bt = pd.concat(rows).sort_index() if rows else pd.DataFrame()\n",
    "    return bt, last_fitted_model, last_train_mask\n",
    "\n",
    "\n",
    "# Run backtest\n",
    "bt_rows, last_model, last_train_mask = rolling_monthly_backtest_tree(\n",
    "    X_all, y_all, model=base_model, use_early_stopping=False\n",
    ")\n",
    "\n",
    "bt_rows.head(), bt_rows.tail(), bt_rows.shape\n"
   ],
   "id": "2ed1066fb73bf6e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            y_true      p_up  y_pred    month  train_end  n_train  n_test\n",
       " date                                                                     \n",
       " 2020-03-02       1  0.222219       0  2020-03 2020-03-01      518      22\n",
       " 2020-03-03       1  0.270458       0  2020-03 2020-03-01      518      22\n",
       " 2020-03-04       1  0.267606       0  2020-03 2020-03-01      518      22\n",
       " 2020-03-05       1  0.301312       0  2020-03 2020-03-01      518      22\n",
       " 2020-03-06       1  0.157834       0  2020-03 2020-03-01      518      22,\n",
       "             y_true      p_up  y_pred    month  train_end  n_train  n_test\n",
       " date                                                                     \n",
       " 2025-12-05       0  0.651157       1  2025-12 2025-11-30     1951       9\n",
       " 2025-12-08       0  0.866706       1  2025-12 2025-11-30     1951       9\n",
       " 2025-12-09       0  0.811794       1  2025-12 2025-11-30     1951       9\n",
       " 2025-12-10       0  0.799210       1  2025-12 2025-11-30     1951       9\n",
       " 2025-12-11       0  0.658084       1  2025-12 2025-11-30     1951       9,\n",
       " (1442, 7))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:48:05.005249Z",
     "start_time": "2025-12-27T06:48:04.995907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = bt_rows[\"y_true\"].astype(int).values\n",
    "p_up = bt_rows[\"p_up\"].astype(float).values\n",
    "y_pred = bt_rows[\"y_pred\"].astype(int).values\n",
    "\n",
    "overall = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"n\": len(bt_rows),\n",
    "    \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "    \"log_loss\": float(log_loss(y_true, p_up, labels=[0, 1])),\n",
    "    \"brier\": float(brier_score_loss(y_true, p_up)),\n",
    "    \"mean_p_up\": float(np.mean(p_up)),\n",
    "    \"pos_rate\": float(np.mean(y_true)),\n",
    "}\n",
    "\n",
    "metrics_overall = pd.DataFrame([overall])\n",
    "metrics_overall\n"
   ],
   "id": "74ac1a70a3cfb1f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     model     n  accuracy  log_loss     brier  mean_p_up  pos_rate\n",
       "0  xgboost  1442  0.486824  0.928234  0.323778   0.469575  0.496533"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>n</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>brier</th>\n",
       "      <th>mean_p_up</th>\n",
       "      <th>pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.486824</td>\n",
       "      <td>0.928234</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0.469575</td>\n",
       "      <td>0.496533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:48:05.029245Z",
     "start_time": "2025-12-27T06:48:05.016242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bt = bt_rows.copy()\n",
    "bt[\"bucket\"] = assign_confidence_bucket(bt[\"p_up\"])\n",
    "\n",
    "bucket_metrics = (\n",
    "    bt.groupby(\"bucket\", observed=True)\n",
    "      .apply(lambda g: pd.Series({\n",
    "          \"n\": len(g),\n",
    "          \"coverage\": len(g) / len(bt),\n",
    "          \"accuracy\": (g[\"y_pred\"] == g[\"y_true\"]).mean(),\n",
    "          \"avg_p_up\": g[\"p_up\"].mean(),\n",
    "          \"pos_rate\": g[\"y_true\"].mean(),\n",
    "          \"avg_confidence\": np.maximum(g[\"p_up\"], 1 - g[\"p_up\"]).mean(),\n",
    "      }))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "bucket_metrics\n"
   ],
   "id": "85738d9affaa3103",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/shg_zsjd50n33s0b7vfh1h800000gn/T/ipykernel_68274/3653474026.py:6: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        bucket      n  coverage  accuracy  avg_p_up  pos_rate  avg_confidence\n",
       "0  [0.00,0.40)  637.0  0.441748  0.516484  0.212887  0.483516        0.787113\n",
       "1  [0.40,0.45)   89.0  0.061720  0.404494  0.424674  0.595506        0.575326\n",
       "2  [0.45,0.55)  140.0  0.097087  0.421429  0.503140  0.550000        0.524958\n",
       "3  [0.55,0.60)   76.0  0.052705  0.434211  0.574249  0.434211        0.574249\n",
       "4  [0.60,1.00]  500.0  0.346741  0.490000  0.779280  0.490000        0.779280"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket</th>\n",
       "      <th>n</th>\n",
       "      <th>coverage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>avg_p_up</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>avg_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.00,0.40)</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0.441748</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.212887</td>\n",
       "      <td>0.483516</td>\n",
       "      <td>0.787113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.40,0.45)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.061720</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>0.424674</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.575326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.45,0.55)</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.503140</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.524958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.55,0.60)</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.052705</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.574249</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.574249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.60,1.00]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.346741</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.779280</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.779280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:48:05.155954Z",
     "start_time": "2025-12-27T06:48:05.146090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importance = None\n",
    "\n",
    "if MODEL_NAME == \"xgboost\":\n",
    "    # Use built-in importance (gain) from the last fitted model\n",
    "    booster = last_model.get_booster()\n",
    "    score = booster.get_score(importance_type=\"gain\")\n",
    "    imp = pd.Series(score, name=\"gain\").sort_values(ascending=False)\n",
    "\n",
    "    # XGBoost feature names sometimes come as \"f0, f1...\" if not passed\n",
    "    # Ensure mapping to actual names if needed\n",
    "    if imp.index.str.match(r\"f\\d+\").all():\n",
    "        mapping = {f\"f{i}\": col for i, col in enumerate(feature_cols)}\n",
    "        imp.index = imp.index.map(mapping)\n",
    "\n",
    "    importance = imp.reset_index().rename(columns={\"index\": \"feature\"})\n",
    "else:\n",
    "    # Controlled permutation importance on a small recent subset of training data (deterministic slice)\n",
    "    # to avoid heavy runtime.\n",
    "    train_X = X_all.loc[last_train_mask]\n",
    "    train_y = y_all.loc[last_train_mask]\n",
    "\n",
    "    # Use the last 252 observations for importance (recent regime)\n",
    "    if len(train_X) >= 252:\n",
    "        X_imp = train_X.iloc[-252:]\n",
    "        y_imp = train_y.iloc[-252:]\n",
    "    else:\n",
    "        X_imp, y_imp = train_X, train_y\n",
    "\n",
    "    r = permutation_importance(\n",
    "        last_model, X_imp, y_imp,\n",
    "        n_repeats=5,\n",
    "        random_state=RANDOM_SEED,\n",
    "        scoring=\"neg_log_loss\"\n",
    "    )\n",
    "    importance = (\n",
    "        pd.DataFrame({\"feature\": X_imp.columns, \"importance\": r.importances_mean})\n",
    "          .sort_values(\"importance\", ascending=False)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "importance.head(20)\n"
   ],
   "id": "d378bf5340fb7841",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            feature      gain\n",
       "0             value  6.758736\n",
       "1       is_high_vol  6.672000\n",
       "2           mom_21d  6.606195\n",
       "3           vol_21d  6.278761\n",
       "4           vol_63d  6.090878\n",
       "5    vol_21_med_252  5.958591\n",
       "6           ret_21d  5.791118\n",
       "7             month  5.724078\n",
       "8           vol_10d  5.240837\n",
       "9   vol_ratio_21_63  5.106203\n",
       "10           vol_5d  4.640314\n",
       "11          mom_10d  4.310676\n",
       "12          ret_10d  4.038233\n",
       "13           ret_5d  4.014171\n",
       "14           ret_3d  4.007792\n",
       "15      zret_1d_21d  3.528995\n",
       "16           mom_5d  3.418825\n",
       "17           ret_1d  3.367759\n",
       "18      zret_1d_63d  3.110466\n",
       "19      day_of_week  3.092267"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>value</td>\n",
       "      <td>6.758736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_high_vol</td>\n",
       "      <td>6.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom_21d</td>\n",
       "      <td>6.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vol_21d</td>\n",
       "      <td>6.278761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vol_63d</td>\n",
       "      <td>6.090878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vol_21_med_252</td>\n",
       "      <td>5.958591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ret_21d</td>\n",
       "      <td>5.791118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>month</td>\n",
       "      <td>5.724078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vol_10d</td>\n",
       "      <td>5.240837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vol_ratio_21_63</td>\n",
       "      <td>5.106203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vol_5d</td>\n",
       "      <td>4.640314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mom_10d</td>\n",
       "      <td>4.310676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ret_10d</td>\n",
       "      <td>4.038233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ret_5d</td>\n",
       "      <td>4.014171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ret_3d</td>\n",
       "      <td>4.007792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zret_1d_21d</td>\n",
       "      <td>3.528995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mom_5d</td>\n",
       "      <td>3.418825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ret_1d</td>\n",
       "      <td>3.367759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zret_1d_63d</td>\n",
       "      <td>3.110466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>3.092267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T06:48:05.238302Z",
     "start_time": "2025-12-27T06:48:05.227274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bt_rows.to_csv(BACKTEST_ROWS_CSV, index=True)\n",
    "metrics_overall.to_csv(METRICS_OVERALL_CSV, index=False)\n",
    "bucket_metrics.to_csv(METRICS_BUCKETS_CSV, index=False)\n",
    "\n",
    "if importance is not None:\n",
    "    importance.to_csv(IMPORTANCE_CSV, index=False)\n"
   ],
   "id": "7ef3a6c093c213f5",
   "outputs": [],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
